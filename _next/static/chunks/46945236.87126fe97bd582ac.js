"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[876],{1481:(e,s,t)=>{t.d(s,{BRf:()=>rb,FJW:()=>rV,JP3:()=>rE,MOY:()=>rk,QNG:()=>rB,TUv:()=>ry,V9g:()=>rF,W6E:()=>rS,Yd3:()=>rI,ZIt:()=>rv,_TZ:()=>rD,db0:()=>rP,gqD:()=>rq,jQR:()=>rM,m68:()=>rN,nuw:()=>rG,rKH:()=>rh,vTA:()=>rA,w0O:()=>rj,wju:()=>rC,wrZ:()=>rO,xIA:()=>rT,yGT:()=>rL});var n=t(8810),a=t(2528),l=t(6985),i=t(6602),r=t(46),o=t(3540),c=t(58),d=t(1608),_=t(5182),u=t(6085),p=t(814),m=t(3164),f=t(762),g=t(1025),x=t(7682),w=t(6842),h=t(8909);let M={EncoderOnly:0,EncoderDecoder:1,Seq2Seq:2,Vision2Seq:3,DecoderOnly:4,MaskGeneration:5,ImageTextToText:6,Musicgen:7,MultiModality:8,Phi3V:9},y=new Map,b=new Map,k=new Map;async function v(e,s,t){let i=t.config?.["transformers.js_config"]??{},r=t.device??i.device;r&&"string"!=typeof r&&(r.hasOwnProperty(s)?r=r[s]:(console.warn(`device not specified for "${s}". Using the default device.`),r=null));let c=r??(x.O.IS_NODE_ENV?"cpu":"wasm"),d=(0,a.ow)(c),_=t.dtype??i.dtype;if("string"!=typeof _&&(_&&_.hasOwnProperty(s)?_=_[s]:(_=l.Vd[c]??l.hL.fp32,console.warn(`dtype not specified for "${s}". Using the default dtype (${_}) for this device (${c}).`))),_===l.hL.auto){let e=i.dtype;"string"!=typeof e&&(e=e[s]),_=e&&e!==l.hL.auto&&l.hL.hasOwnProperty(e)?e:l.Vd[c]??l.hL.fp32}let u=_;if(l.EC.hasOwnProperty(u)){if(u===l.hL.fp16&&"webgpu"===c&&!await (0,l.As)())throw Error(`The device (${c}) does not support fp16.`)}else throw Error(`Invalid dtype: ${u}. Should be one of: ${Object.keys(l.hL).join(", ")}`);let p=i.kv_cache_dtype?"string"==typeof i.kv_cache_dtype?i.kv_cache_dtype:i.kv_cache_dtype[u]??"float32":void 0;if(p&&!["float32","float16"].includes(p))throw Error(`Invalid kv_cache_dtype: ${p}. Should be one of: float32, float16`);let m=l.EC[u],f=`${t.subfolder??""}/${s}${m}.onnx`,g={...t.session_options};g.executionProviders??=d;let w=i.free_dimension_overrides;w?g.freeDimensionOverrides??=w:c.startsWith("webnn")&&!g.freeDimensionOverrides&&console.warn('WebNN does not currently support dynamic shapes and requires `free_dimension_overrides` to be set in config.json as a field within "transformers.js_config". When `free_dimension_overrides` is not set, you may experience significant performance degradation.');let h=(0,o.Yw)(e,f,!0,t),M=t.use_external_data_format??i.use_external_data_format,y=[];if(M&&(!0===M||"object"==typeof M&&M.hasOwnProperty(s)&&!0===M[s])){if(x.O.IS_NODE_ENV)throw Error("External data format is not yet supported in Node.js");let n=`${s}${m}.onnx_data`,a=`${t.subfolder??""}/${n}`;y.push(new Promise(async(s,l)=>{s({path:n,data:await (0,o.Yw)(e,a,!0,t)})}))}else void 0!==g.externalData&&(y=g.externalData.map(async s=>{if("string"==typeof s.data){let n=await (0,o.Yw)(e,s.data,!0,t);return{...s,data:n}}return s}));if(y.length>0&&(g.externalData=await Promise.all(y)),"webgpu"===c){let e=(0,n.dO)(t.config,{prefix:"present"});if(Object.keys(e).length>0&&!(0,a.qX)()){let s={};for(let t in e)s[t]="gpu-buffer";g.preferredOutputLocation=s}}return{buffer:await h,session_options:g,session_config:{dtype:u,kv_cache_dtype:p}}}async function F(e,s,t){return Object.fromEntries(await Promise.all(Object.keys(s).map(async n=>{let{buffer:l,session_options:i,session_config:r}=await v(e,s[n],t);return[n,await (0,a.We)(l,i,r)]})))}async function S(e,s,t){return Object.fromEntries(await Promise.all(Object.keys(s).map(async n=>{let a=await (0,o.wc)(e,s[n],!1,t);return[n,a]})))}async function C(e,s){let t=function(e,s){let t=Object.create(null),n=[];for(let l of e.inputNames){let e=s[l];if(!(e instanceof u.qY)){n.push(l);continue}t[l]=(0,a.qX)()?e.clone():e}if(n.length>0)throw Error(`An error occurred during model execution: "Missing the following inputs: ${n.join(", ")}.`);let l=Object.keys(s).length,i=e.inputNames.length;if(l>i){let t=Object.keys(s).filter(s=>!e.inputNames.includes(s));console.warn(`WARNING: Too many inputs were provided (${l} > ${i}). The following inputs will be ignored: "${t.join(", ")}".`)}return t}(e,s);try{let s=Object.fromEntries(Object.entries(t).map(([e,s])=>[e,s.ort_tensor])),n=await e.run(s);return n=function e(s){for(let t in s)(0,a.lt)(s[t])?s[t]=new u.qY(s[t]):"object"==typeof s[t]&&e(s[t]);return s}(n)}catch(s){let e=Object.fromEntries(Object.entries(t).map(([e,{type:s,dims:t,data:n}])=>[e,{type:s,dims:t,data:n}]));throw console.error(`An error occurred during model execution: "${s}".`),console.error("Inputs given to model:",e),s}}function L(e){if(e instanceof u.qY)return e;if(0===e.length)throw Error("items must be non-empty");if(!Array.isArray(e[0]))return new u.qY("int64",BigInt64Array.from(e.map(e=>BigInt(e))),[1,e.length]);if(e.some(s=>s.length!==e[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new u.qY("int64",BigInt64Array.from(e.flat().map(e=>BigInt(e))),[e.length,e[0].length])}function P(e){return new u.qY("bool",[e],[1])}async function E(e,s){let{encoder_outputs:t,input_ids:n,decoder_input_ids:a,...l}=s;if(!t){let n=(0,r.Up)(s,e.sessions.model.inputNames);t=(await A(e,n)).last_hidden_state}return l.input_ids=a,l.encoder_hidden_states=t,e.sessions.decoder_model_merged.inputNames.includes("encoder_attention_mask")&&(l.encoder_attention_mask=s.attention_mask),await O(e,l,!0)}async function A(e,s){let t=e.sessions.model,n=(0,r.Up)(s,t.inputNames);if(t.inputNames.includes("inputs_embeds")&&!n.inputs_embeds){if(!s.input_ids)throw Error("Both `input_ids` and `inputs_embeds` are missing in the model inputs.");n.inputs_embeds=await e.encode_text({input_ids:s.input_ids})}if(t.inputNames.includes("token_type_ids")&&!n.token_type_ids){if(!n.input_ids)throw Error("Both `input_ids` and `token_type_ids` are missing in the model inputs.");n.token_type_ids=(0,u.aF)(n.input_ids)}if(t.inputNames.includes("pixel_mask")&&!n.pixel_mask){if(!n.pixel_values)throw Error("Both `pixel_values` and `pixel_mask` are missing in the model inputs.");let e=n.pixel_values.dims;n.pixel_mask=(0,u.S)([e[0],e[2],e[3]])}return await C(t,n)}async function O(e,s,t=!1){let n=e.sessions[t?"decoder_model_merged":"model"],{past_key_values:a,...l}=s;if(n.inputNames.includes("use_cache_branch")&&(l.use_cache_branch=P(!!a)),n.inputNames.includes("position_ids")&&l.attention_mask&&!l.position_ids){let s="paligemma"===e.config.model_type?1:0;l.position_ids=function(e,s=null,t=0){let{input_ids:n,inputs_embeds:a,attention_mask:l}=e,{data:i,dims:r}=q(l,t),o=new u.qY("int64",i,r);if(s){let e=-(n??a).dims.at(1);o=o.slice(null,[e,null])}return o}(l,a,s)}e.addPastKeyValues(l,a);let i=(0,r.Up)(l,n.inputNames);return await C(n,i)}function T({image_token_id:e,inputs_embeds:s,image_features:t,input_ids:n,attention_mask:a}){let l=n.tolist().map(s=>s.reduce((s,t,n)=>(t==e&&s.push(n),s),[])),i=l.reduce((e,s)=>e+s.length,0),r=t.dims[0];if(i!==r)throw Error(`Image features and image tokens do not match: tokens: ${i}, features ${r}`);let o=0;for(let e=0;e<l.length;++e){let n=l[e],a=s[e];for(let e=0;e<n.length;++e)a[n[e]].data.set(t[o++].data)}return{inputs_embeds:s,attention_mask:a}}async function I(e,{input_ids:s=null,attention_mask:t=null,pixel_values:n=null,position_ids:a=null,inputs_embeds:l=null,past_key_values:i=null,generation_config:r=null,logits_processor:o=null,...c}){if(!l){if(l=await e.encode_text({input_ids:s,...c}),n&&1!==s.dims[1]){let a=await e.encode_image({pixel_values:n,...c});({inputs_embeds:l,attention_mask:t}=e._merge_input_ids_with_image_features({image_features:a,inputs_embeds:l,input_ids:s,attention_mask:t}))}else if(i&&n&&1===s.dims[1]){let e=s.dims[1],n=Object.values(i)[0].dims.at(-2);t=(0,u.$q)([(0,u.S)([s.dims[0],n]),t.slice(null,[t.dims[1]-e,t.dims[1]])],1)}}if(!a&&"qwen2_vl"===e.config.model_type){let{image_grid_thw:n,video_grid_thw:l}=c;[a]=e.get_rope_index(s,n,l,t)}return await O(e,{inputs_embeds:l,past_key_values:i,attention_mask:t,position_ids:a,generation_config:r,logits_processor:o},!0)}function q(e,s=0){let[t,n]=e.dims,a=e.data,l=new BigInt64Array(a.length);for(let e=0;e<t;++e){let t=e*n,i=BigInt(s);for(let e=0;e<n;++e){let s=t+e;0n===a[s]?l[s]=BigInt(1):(l[s]=i,i+=a[s])}}return{data:l,dims:e.dims}}function D(e,s,t,n){if(t.past_key_values){let s=Object.values(t.past_key_values)[0].dims.at(-2),{input_ids:n,attention_mask:a}=t;if(a&&a.dims[1]>n.dims[1]);else if(s<n.dims[1])t.input_ids=n.slice(null,[s,null]);else if(null!=e.config.image_token_index&&n.data.some(s=>s==e.config.image_token_index)){let a=e.config.num_image_tokens;if(!a)throw Error("`num_image_tokens` is missing in the model configuration.");let l=n.dims[1]-(s-a);t.input_ids=n.slice(null,[-l,null]),t.attention_mask=(0,u.S)([1,s+l])}}return t}function N(e,s,t,n){return t.past_key_values&&(s=s.map(e=>[e.at(-1)])),{...t,decoder_input_ids:L(s)}}function G(e,...s){return e.config.is_encoder_decoder?N(e,...s):D(e,...s)}function V(e,s,t,n){let a=!!t.past_key_values;return null!==n.guidance_scale&&n.guidance_scale>1&&(a?t.input_ids=(0,u.$q)([t.input_ids,t.input_ids],0):(t.input_ids=(0,u.$q)([t.input_ids,(0,u.ck)(t.input_ids,BigInt(n.pad_token_id))],0),t.attention_mask=(0,u.$q)([t.attention_mask,(0,u.ck)(t.attention_mask,0n)],0))),(a||!t.pixel_values)&&(t.pixel_values=(0,u.a2)([0,0,3,384,384],1)),a&&(t.images_seq_mask=new u.qY("bool",[,].fill(!0).fill(!1,0,1),[1,1]),t.images_emb_mask=new u.qY("bool",[].fill(!1),[1,1,0])),t}class B extends i.b{main_input_name="input_ids";forward_params=["input_ids","attention_mask"];constructor(e,s,t){super(),this.config=e,this.sessions=s,this.configs=t;let n=k.get(this.constructor),a=y.get(n);switch(this.can_generate=!1,this._forward=null,this._prepare_inputs_for_generation=null,a){case M.DecoderOnly:this.can_generate=!0,this._forward=O,this._prepare_inputs_for_generation=D;break;case M.Seq2Seq:case M.Vision2Seq:case M.Musicgen:this.can_generate=!0,this._forward=E,this._prepare_inputs_for_generation=N;break;case M.EncoderDecoder:this._forward=E;break;case M.ImageTextToText:this.can_generate=!0,this._forward=I,this._prepare_inputs_for_generation=G;break;case M.Phi3V:this.can_generate=!0,this._prepare_inputs_for_generation=G;break;case M.MultiModality:this.can_generate=!0,this._prepare_inputs_for_generation=V;break;default:this._forward=A}this.can_generate&&this.forward_params.push("past_key_values"),this.custom_config=this.config["transformers.js_config"]??{}}async dispose(){let e=[];for(let s of Object.values(this.sessions))s?.handler?.dispose&&e.push(s.handler.dispose());return await Promise.all(e)}static async from_pretrained(e,{progress_callback:s=null,config:t=null,cache_dir:a=null,local_files_only:l=!1,revision:i="main",model_file_name:r=null,subfolder:o="onnx",device:d=null,dtype:_=null,use_external_data_format:u=null,session_options:p={}}={}){let m,f={progress_callback:s,config:t,cache_dir:a,local_files_only:l,revision:i,model_file_name:r,subfolder:o,device:d,dtype:_,use_external_data_format:u,session_options:p},g=k.get(this),x=y.get(g);if(t=f.config=await n.EJ.from_pretrained(e,f),x===M.DecoderOnly)m=await Promise.all([F(e,{model:f.model_file_name??"model"},f),S(e,{generation_config:"generation_config.json"},f)]);else if(x===M.Seq2Seq||x===M.Vision2Seq)m=await Promise.all([F(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},f),S(e,{generation_config:"generation_config.json"},f)]);else if(x===M.MaskGeneration)m=await Promise.all([F(e,{model:"vision_encoder",prompt_encoder_mask_decoder:"prompt_encoder_mask_decoder"},f)]);else if(x===M.EncoderDecoder)m=await Promise.all([F(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},f)]);else if(x===M.ImageTextToText){let s={embed_tokens:"embed_tokens",vision_encoder:"vision_encoder",decoder_model_merged:"decoder_model_merged"};t.is_encoder_decoder&&(s.model="encoder_model"),m=await Promise.all([F(e,s,f),S(e,{generation_config:"generation_config.json"},f)])}else if(x===M.Musicgen)m=await Promise.all([F(e,{model:"text_encoder",decoder_model_merged:"decoder_model_merged",encodec_decode:"encodec_decode"},f),S(e,{generation_config:"generation_config.json"},f)]);else if(x===M.MultiModality)m=await Promise.all([F(e,{prepare_inputs_embeds:"prepare_inputs_embeds",model:"language_model",lm_head:"lm_head",gen_head:"gen_head",gen_img_embeds:"gen_img_embeds",image_decode:"image_decode"},f),S(e,{generation_config:"generation_config.json"},f)]);else if(x===M.Phi3V)m=await Promise.all([F(e,{prepare_inputs_embeds:"prepare_inputs_embeds",model:"model",vision_encoder:"vision_encoder"},f),S(e,{generation_config:"generation_config.json"},f)]);else{if(x!==M.EncoderOnly){let e=g??t?.model_type;"custom"!==e&&console.warn(`Model type for '${e}' not found, assuming encoder-only architecture. Please report this at ${c.OY}.`)}m=await Promise.all([F(e,{model:f.model_file_name??"model"},f)])}return new this(t,...m)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}get generation_config(){return this.configs?.generation_config??null}_get_logits_warper(e){let s=new d.VT;return null!==e.temperature&&1!==e.temperature&&s.push(new d._0(e.temperature)),null!==e.top_k&&0!==e.top_k&&s.push(new d.CO(e.top_k)),null!==e.top_p&&e.top_p<1&&s.push(new d.HB(e.top_p)),s}_get_logits_processor(e,s,t=null){let n=new d.VT;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&n.push(new d.hK(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&n.push(new d.Y8(e.no_repeat_ngram_size)),null!==e.bad_words_ids&&n.push(new d.SP(e.bad_words_ids,e.eos_token_id)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&n.push(new d.pe(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&n.push(new d.z_(s,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&n.push(new d.zM(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&n.push(new d.uB(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let t=s>1||null===e.forced_bos_token_id?s:s+1;n.push(new d.S3(e.begin_suppress_tokens,t))}return null!==e.guidance_scale&&e.guidance_scale>1&&n.push(new d.io(e.guidance_scale)),null!==t&&n.extend(t),n}_prepare_generation_config(e,s,t=_.F){let n={...this.config};for(let e of["decoder","generator","text_config"])e in n&&Object.assign(n,n[e]);let a=new t(n);return Object.assign(a,this.generation_config??{}),e&&Object.assign(a,e),s&&Object.assign(a,(0,r.Up)(s,Object.getOwnPropertyNames(a))),a}_get_stopping_criteria(e,s=null){let t=new f.Ep;return null!==e.max_length&&t.push(new f._M(e.max_length,this.config.max_position_embeddings??null)),null!==e.eos_token_id&&t.push(new f.qj(e.eos_token_id)),s&&t.extend(s),t}_validate_model_class(){if(!this.can_generate){let e=k.get(this.constructor),s=new Set,t=this.config.model_type;for(let e of[i3,i8,i1,iJ]){let n=e.get(t);n&&s.add(n[0])}let n=`The current model class (${e}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;throw s.size>0&&(n+=` Please use the following class instead: ${[...s].join(", ")}`),Error(n)}}prepare_inputs_for_generation(...e){return this._prepare_inputs_for_generation(this,...e)}_update_model_kwargs_for_generation({generated_input_ids:e,outputs:s,model_inputs:t,is_encoder_decoder:n}){return t.past_key_values=this.getPastKeyValues(s,t.past_key_values),t.input_ids=new u.qY("int64",e.flat(),[e.length,1]),n||(t.attention_mask=(0,u.$q)([t.attention_mask,(0,u.S)([t.attention_mask.dims[0],1])],1)),t.position_ids=null,t}_prepare_model_inputs({inputs:e,bos_token_id:s,model_kwargs:t}){let n=(0,r.Up)(t,this.forward_params),a=this.main_input_name;if(a in n){if(e)throw Error("`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. Make sure to either pass {inputs} or {input_name}=...")}else n[a]=e;return{inputs_tensor:n[a],model_inputs:n,model_input_name:a}}async _prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:e,model_inputs:s,model_input_name:t,generation_config:n}){if(this.sessions.model.inputNames.includes("inputs_embeds")&&!s.inputs_embeds&&"_prepare_inputs_embeds"in this){let{input_ids:e,pixel_values:t,attention_mask:n,...a}=s,l=await this._prepare_inputs_embeds(s);s={...a,...(0,r.Up)(l,["inputs_embeds","attention_mask"])}}let{last_hidden_state:a}=await A(this,s);if(null!==n.guidance_scale&&n.guidance_scale>1)a=(0,u.$q)([a,(0,u.ck)(a,0)],0),"attention_mask"in s&&(s.attention_mask=(0,u.$q)([s.attention_mask,(0,u.aF)(s.attention_mask)],0));else if(s.decoder_input_ids){let e=L(s.decoder_input_ids).dims[0];if(e!==a.dims[0]){if(1!==a.dims[0])throw Error(`The encoder outputs have a different batch size (${a.dims[0]}) than the decoder inputs (${e}).`);a=(0,u.$q)(Array.from({length:e},()=>a),0)}}return s.encoder_outputs=a,s}_prepare_decoder_input_ids_for_generation({batch_size:e,model_input_name:s,model_kwargs:t,decoder_start_token_id:n,bos_token_id:a,generation_config:l}){let{decoder_input_ids:i,...r}=t;if(!(i instanceof u.qY)){if(i)Array.isArray(i[0])||(i=Array.from({length:e},()=>i));else if(n??=a,"musicgen"===this.config.model_type)i=Array.from({length:e*this.config.decoder.num_codebooks},()=>[n]);else if(Array.isArray(n)){if(n.length!==e)throw Error(`\`decoder_start_token_id\` expcted to have length ${e} but got ${n.length}`);i=n}else i=Array.from({length:e},()=>[n]);i=L(i)}return t.decoder_attention_mask=(0,u.oC)(i),{input_ids:i,model_inputs:r}}async generate({inputs:e=null,generation_config:s=null,logits_processor:t=null,stopping_criteria:n=null,streamer:a=null,...l}){let i,r;this._validate_model_class(),s=this._prepare_generation_config(s,l);let{inputs_tensor:o,model_inputs:c,model_input_name:d}=this._prepare_model_inputs({inputs:e,model_kwargs:l}),_=this.config.is_encoder_decoder;_&&("encoder_outputs"in c||(c=await this._prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:o,model_inputs:c,model_input_name:d,generation_config:s}))),_?{input_ids:i,model_inputs:c}=this._prepare_decoder_input_ids_for_generation({batch_size:c[d].dims.at(0),model_input_name:d,model_kwargs:c,decoder_start_token_id:s.decoder_start_token_id,bos_token_id:s.bos_token_id,generation_config:s}):i=c[d];let p=i.dims.at(-1);null!==s.max_new_tokens&&(s.max_length=p+s.max_new_tokens);let m=this._get_logits_processor(s,p,t),f=this._get_stopping_criteria(s,n),x=c[d].dims.at(0),w=g.f.getSampler(s),h=Array(x).fill(0),M=i.tolist();a&&a.put(M);let y={};for(;;){if(c=this.prepare_inputs_for_generation(M,c,s),r=await this.forward(c),s.output_attentions&&s.return_dict_in_generate){let e=this.getAttentions(r);for(let s in e)s in y||(y[s]=[]),y[s].push(e[s])}let e=m(M,r.logits.slice(null,-1,null)),t=[];for(let s=0;s<e.dims.at(0);++s){let n=e[s];for(let[e,a]of(await w(n))){let n=BigInt(e);h[s]+=a,M[s].push(n),t.push([n]);break}}if(a&&a.put(t),f(M).every(e=>e))break;c=this._update_model_kwargs_for_generation({generated_input_ids:t,outputs:r,model_inputs:c,is_encoder_decoder:_})}a&&a.end();let b=this.getPastKeyValues(r,c.past_key_values,!0),k=new u.qY("int64",M.flat(),[M.length,M[0].length]);if(s.return_dict_in_generate)return{sequences:k,past_key_values:b,...y};for(let e of Object.values(r))"gpu-buffer"===e.location&&e.dispose();return k}getPastKeyValues(e,s,t=!1){let n=Object.create(null);for(let a in e)if(a.startsWith("present")){let l=a.replace("present","past_key_values"),i=a.includes("encoder");if(i&&s?n[l]=s[l]:n[l]=e[a],s&&(!i||t)){let e=s[l];"gpu-buffer"===e.location&&e.dispose()}}return n}getAttentions(e){let s={};for(let t of["cross_attentions","encoder_attentions","decoder_attentions"])for(let n in e)n.startsWith(t)&&(t in s||(s[t]=[]),s[t].push(e[n]));return s}addPastKeyValues(e,s){if(s)Object.assign(e,s);else{let s=this.sessions.decoder_model_merged??this.sessions.model,t=s?.config?.kv_cache_dtype??"float32",a="float16"===t?new Uint16Array:[],l=(e[this.main_input_name]??e.attention_mask)?.dims?.[0]??1,i=(0,n.dO)(this.config,{batch_size:l});for(let s in i)e[s]=new u.qY(t,a,i[s])}}async encode_image({pixel_values:e}){let s=(await C(this.sessions.vision_encoder,{pixel_values:e})).image_features;return this.config.num_image_tokens||(console.warn(`The number of image tokens was not set in the model configuration. Setting it to the number of features detected by the vision encoder (${s.dims[1]}).`),this.config.num_image_tokens=s.dims[1]),s}async encode_text({input_ids:e}){return(await C(this.sessions.embed_tokens,{input_ids:e})).inputs_embeds}}class j{}class $ extends B{}class Y extends ${}class W extends ${async _call(e){return new rR(await super._call(e))}}class R extends ${async _call(e){return new r$(await super._call(e))}}class z extends ${async _call(e){return new rW(await super._call(e))}}class U extends ${async _call(e){return new rz(await super._call(e))}}class Q extends B{}class X extends Q{}class H extends Q{async _call(e){return new rR(await super._call(e))}}class J extends Q{async _call(e){return new r$(await super._call(e))}}class K extends Q{async _call(e){return new rW(await super._call(e))}}class Z extends B{}class ee extends Z{}class es extends B{}class et extends es{}class en extends es{async _call(e){return new rR(await super._call(e))}}class ea extends es{async _call(e){return new r$(await super._call(e))}}class el extends es{async _call(e){return new rW(await super._call(e))}}class ei extends es{async _call(e){return new rz(await super._call(e))}}class er extends B{}class eo extends er{}class ec extends er{async _call(e){return new rR(await super._call(e))}}class ed extends er{async _call(e){return new r$(await super._call(e))}}class e_ extends er{async _call(e){return new rW(await super._call(e))}}class eu extends er{async _call(e){return new rz(await super._call(e))}}class ep extends B{}class em extends ep{}class ef extends ep{async _call(e){return new rR(await super._call(e))}}class eg extends ep{async _call(e){return new r$(await super._call(e))}}class ex extends ep{async _call(e){return new rW(await super._call(e))}}class ew extends ep{async _call(e){return new rz(await super._call(e))}}class eh extends B{}class eM extends eh{}class ey extends eh{async _call(e){return new rR(await super._call(e))}}class eb extends eh{async _call(e){return new r$(await super._call(e))}}class ek extends eh{async _call(e){return new rW(await super._call(e))}}class ev extends eh{async _call(e){return new rz(await super._call(e))}}class eF extends B{}class eS extends eF{}class eC extends eF{async _call(e){return new rR(await super._call(e))}}class eL extends eF{async _call(e){return new r$(await super._call(e))}}class eP extends eF{async _call(e){return new rW(await super._call(e))}}class eE extends eF{async _call(e){return new rz(await super._call(e))}}class eA extends B{}class eO extends eA{}class eT extends eA{async _call(e){return new rR(await super._call(e))}}class eI extends eA{async _call(e){return new r$(await super._call(e))}}class eq extends eA{async _call(e){return new rW(await super._call(e))}}class eD extends eA{async _call(e){return new rz(await super._call(e))}}class eN extends B{}class eG extends eN{}class eV extends eN{async _call(e){return new r$(await super._call(e))}}class eB extends eN{async _call(e){return new rW(await super._call(e))}}class ej extends eN{async _call(e){return new rz(await super._call(e))}}class e$ extends eN{async _call(e){return new rR(await super._call(e))}}class eY extends B{}class eW extends eY{}class eR extends eY{async _call(e){return new rR(await super._call(e))}}class ez extends eY{async _call(e){return new r$(await super._call(e))}}class eU extends eY{async _call(e){return new rW(await super._call(e))}}class eQ extends B{}class eX extends eQ{}class eH extends eQ{async _call(e){return new rR(await super._call(e))}}class eJ extends eQ{async _call(e){return new r$(await super._call(e))}}class eK extends eQ{async _call(e){return new rz(await super._call(e))}}class eZ extends B{}class e0 extends eZ{}class e2 extends eZ{async _call(e){return new rR(await super._call(e))}}class e1 extends eZ{async _call(e){return new r$(await super._call(e))}}class e3 extends eZ{async _call(e){return new rW(await super._call(e))}}class e6 extends eZ{async _call(e){return new rz(await super._call(e))}}class e4 extends B{}class e5 extends e4{}class e8 extends e4{async _call(e){return new rR(await super._call(e))}}class e9 extends e4{async _call(e){return new r$(await super._call(e))}}class e7 extends e4{async _call(e){return new rz(await super._call(e))}}class se extends B{}class ss extends se{}class st extends se{async _call(e){return new r$(await super._call(e))}}class sn extends se{async _call(e){return new rz(await super._call(e))}}class sa extends se{async _call(e){return new rR(await super._call(e))}}class sl extends B{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"]}class si extends sl{}class sr extends sl{}class so extends B{}class sc extends so{}class sd extends so{}class s_ extends B{}class su extends s_{}class sp extends s_{}class sm extends B{}class sf extends sm{}class sg extends sm{}class sx extends sm{async _call(e){return new r$(await super._call(e))}}class sw extends B{}class sh extends sw{}class sM extends sw{}class sy extends sw{async _call(e){return new r$(await super._call(e))}}class sb extends sw{}class sk extends B{}class sv extends sk{}class sF extends sk{}class sS extends B{}class sC extends sS{}class sL extends sS{}class sP extends B{}class sE extends sP{}class sA extends sP{async _call(e){return new rR(await super._call(e))}}class sO extends sP{async _call(e){return new r$(await super._call(e))}}class sT extends sP{async _call(e){return new rW(await super._call(e))}}class sI extends sP{async _call(e){return new rz(await super._call(e))}}class sq extends B{}class sD extends sq{}class sN extends sq{async _call(e){return new rR(await super._call(e))}}class sG extends sq{async _call(e){return new r$(await super._call(e))}}class sV extends sq{async _call(e){return new rW(await super._call(e))}}class sB extends sq{async _call(e){return new rz(await super._call(e))}}class sj extends B{}class s$ extends sj{}class sY extends sj{async _call(e){return new rR(await super._call(e))}}class sW extends sj{async _call(e){return new r$(await super._call(e))}}class sR extends sj{async _call(e){return new rW(await super._call(e))}}class sz extends sj{async _call(e){return new rz(await super._call(e))}}class sU extends B{}class sQ extends sU{}class sX extends sU{}class sH extends B{requires_attention_mask=!1;main_input_name="input_features";forward_params=["input_features","attention_mask","decoder_input_ids","decoder_attention_mask","past_key_values"]}class sJ extends sH{}class sK extends sH{_prepare_generation_config(e,s){return super._prepare_generation_config(e,s,w.d)}_retrieve_init_tokens(e){let s=[e.decoder_start_token_id],t=e.language,n=e.task;if(e.is_multilingual){t||(console.warn("No language specified - defaulting to English (en)."),t="en");let a=(0,h.KW)(t),l=`<|${a}|>`;s.push(e.lang_to_id[l]),s.push(e.task_to_id[n??"transcribe"])}else if(t||n)throw Error("Cannot specify `task` or `language` for an English-only model. If the model is intended to be multilingual, pass `is_multilingual=true` to generate, or update the generation config.");return!e.return_timestamps&&e.no_timestamps_token_id&&s.at(-1)!==e.no_timestamps_token_id?s.push(e.no_timestamps_token_id):e.return_timestamps&&s.at(-1)===e.no_timestamps_token_id&&(console.warn("<|notimestamps|> prompt token is removed from generation_config since `return_timestamps` is set to `true`."),s.pop()),s.filter(e=>null!=e)}async generate({inputs:e=null,generation_config:s=null,logits_processor:t=null,stopping_criteria:n=null,...a}){s=this._prepare_generation_config(s,a);let l=a.decoder_input_ids??this._retrieve_init_tokens(s);if(s.return_timestamps&&(t??=new d.VT).push(new d.Fg(s,l)),s.begin_suppress_tokens&&(t??=new d.VT).push(new d.S3(s.begin_suppress_tokens,l.length)),s.return_token_timestamps){if(!s.alignment_heads)throw Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");"translate"===s.task&&console.warn("Token-level timestamps may not be reliable for task 'translate'."),s.output_attentions=!0,s.return_dict_in_generate=!0}let i=await super.generate({inputs:e,generation_config:s,logits_processor:t,decoder_input_ids:l,...a});return s.return_token_timestamps&&(i.token_timestamps=this._extract_token_timestamps(i,s.alignment_heads,s.num_frames)),i}_extract_token_timestamps(e,s,t=null,n=.02){if(!e.cross_attentions)throw Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");null==t&&console.warn("`num_frames` has not been set, meaning the entire audio will be analyzed. This may lead to inaccurate token-level timestamps for short audios (< 30 seconds).");let a=this.config.median_filter_width;void 0===a&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),a=7);let l=e.cross_attentions,i=Array.from({length:this.config.decoder_layers},(e,s)=>(0,u.$q)(l.map(e=>e[s]),2)),o=(0,u.t$)(s.map(([e,s])=>{if(e>=i.length)throw Error(`Layer index ${e} is out of bounds for cross attentions (length ${i.length}).`);return t?i[e].slice(null,s,null,[0,t]):i[e].slice(null,s)})).transpose(1,0,2,3),[c,d]=(0,u.cQ)(o,-2,0,!0),_=o.clone();for(let e=0;e<_.dims[0];++e){let s=_[e];for(let t=0;t<s.dims[0];++t){let n=s[t],l=c[e][t][0].data,i=d[e][t][0].data;for(let e=0;e<n.dims[0];++e){let s=n[e].data;for(let e=0;e<s.length;++e)s[e]=(s[e]-i[e])/l[e];s.set((0,m.jV)(s,a))}}}let p=[(0,u.i2)(_,1)],f=e.sequences.dims,g=new u.qY("float32",new Float32Array(f[0]*f[1]),f);for(let e=0;e<f[0];++e){let s=p[e].neg().squeeze_(0),[t,a]=(0,m.Ty)(s.tolist()),l=Array.from({length:t.length-1},(e,s)=>t[s+1]-t[s]),i=(0,r.TR)([1],l).map(e=>!!e),o=[];for(let e=0;e<i.length;++e)i[e]&&o.push(a[e]*n);g[e].data.set(o,1)}return g}}class sZ extends B{requires_attention_mask=!1;main_input_name="input_values";forward_params=["input_values","decoder_input_ids","past_key_values"]}class s0 extends sZ{}class s2 extends B{main_input_name="pixel_values";forward_params=["pixel_values","decoder_input_ids","encoder_hidden_states","past_key_values"]}class s1 extends B{forward_params=["input_ids","attention_mask","pixel_values","position_ids","past_key_values"]}class s3 extends s1{_merge_input_ids_with_image_features({inputs_embeds:e,image_features:s,input_ids:t,attention_mask:n}){let a=this.config.image_token_index,l=t.tolist().map(e=>e.findIndex(e=>e==a)),i=l.every(e=>-1===e),r=l.every(e=>-1!==e);if(!i&&!r)throw Error("Every input should contain either 0 or 1 image token.");if(i)return{inputs_embeds:e,attention_mask:n};let o=[],c=[];for(let t=0;t<l.length;++t){let a=l[t],i=e[t],r=s[t],d=n[t];o.push((0,u.$q)([i.slice([0,a]),r,i.slice([a+1,i.dims[0]])],0)),c.push((0,u.$q)([d.slice([0,a]),(0,u.S)([r.dims[0]]),d.slice([a+1,d.dims[0]])],0))}return{inputs_embeds:(0,u.t$)(o,0),attention_mask:(0,u.t$)(c,0)}}}class s6 extends s3{}class s4 extends s3{}class s5 extends B{forward_params=["input_ids","inputs_embeds","attention_mask","pixel_values","encoder_outputs","decoder_input_ids","decoder_inputs_embeds","decoder_attention_mask","past_key_values"];main_input_name="inputs_embeds"}class s8 extends s5{_merge_input_ids_with_image_features({inputs_embeds:e,image_features:s,input_ids:t,attention_mask:n}){return{inputs_embeds:(0,u.$q)([s,e],1),attention_mask:(0,u.$q)([(0,u.S)(s.dims.slice(0,2)),n],1)}}async _prepare_inputs_embeds({input_ids:e,pixel_values:s,inputs_embeds:t,attention_mask:n}){let a,l;if(!e&&!s)throw Error("Either `input_ids` or `pixel_values` should be provided.");return e&&(a=await this.encode_text({input_ids:e})),s&&(l=await this.encode_image({pixel_values:s})),a&&l?{inputs_embeds:t,attention_mask:n}=this._merge_input_ids_with_image_features({inputs_embeds:a,image_features:l,input_ids:e,attention_mask:n}):t=a||l,{inputs_embeds:t,attention_mask:n}}async forward({input_ids:e,pixel_values:s,attention_mask:t,decoder_input_ids:n,decoder_attention_mask:a,encoder_outputs:l,past_key_values:i,inputs_embeds:r,decoder_inputs_embeds:o}){if(r||({inputs_embeds:r,attention_mask:t}=await this._prepare_inputs_embeds({input_ids:e,pixel_values:s,inputs_embeds:r,attention_mask:t})),!l){let{last_hidden_state:e}=await A(this,{inputs_embeds:r,attention_mask:t});l=e}if(!o){if(!n)throw Error("Either `decoder_input_ids` or `decoder_inputs_embeds` should be provided.");o=await this.encode_text({input_ids:n})}let c={inputs_embeds:o,attention_mask:a,encoder_attention_mask:t,encoder_hidden_states:l,past_key_values:i};return await O(this,c,!0)}}class s9 extends B{forward_params=["input_ids","attention_mask","pixel_values","position_ids","past_key_values"]}class s7 extends s9{_merge_input_ids_with_image_features(e){let s=e.image_features.dims.at(-1),t=e.image_features.view(-1,s);return T({image_token_id:this.config.image_token_index,...e,image_features:t})}}class te extends B{forward_params=["input_ids","attention_mask","pixel_values","pixel_attention_mask","position_ids","past_key_values"]}class ts extends te{async encode_image({pixel_values:e,pixel_attention_mask:s}){return(await C(this.sessions.vision_encoder,{pixel_values:e,pixel_attention_mask:s})).image_features}_merge_input_ids_with_image_features(e){let s=e.image_features.dims.at(-1),t=e.image_features.view(-1,s);return T({image_token_id:this.config.image_token_id,...e,image_features:t})}}class tt extends B{forward_params=["input_ids","inputs_embeds","attention_mask","position_ids","pixel_values","image_sizes","past_key_values"]}class tn extends tt{async forward({input_ids:e=null,attention_mask:s=null,pixel_values:t=null,image_sizes:n=null,position_ids:a=null,inputs_embeds:l=null,past_key_values:i=null,generation_config:r=null,logits_processor:o=null,...c}){if(!l){let s;if(t&&1!==e.dims[1]){if(!n)throw Error("`image_sizes` must be provided when `pixel_values` is provided.");({image_features:s}=await C(this.sessions.vision_encoder,{pixel_values:t,image_sizes:n}))}else{let e=this.config.normalized_config.hidden_size;s=new u.qY("float32",[],[0,e])}({inputs_embeds:l}=await C(this.sessions.prepare_inputs_embeds,{input_ids:e,image_features:s}))}return await O(this,{inputs_embeds:l,past_key_values:i,attention_mask:s,position_ids:a,generation_config:r,logits_processor:o},!1)}}class ta extends B{}class tl extends ta{}class ti extends ta{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"text_model"})}}class tr extends ta{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"vision_model"})}}class to extends B{}class tc extends to{}class td extends to{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"text_model"})}}class t_ extends ta{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"vision_model"})}}class tu extends B{}class tp extends tu{}class tm extends B{}class tf extends tm{async forward(e){let s=!e.input_ids,t=!e.pixel_values;if(s&&t)throw Error("Either `input_ids` or `pixel_values` should be provided.");if(s&&(e.input_ids=(0,u.S)([e.pixel_values.dims[0],1])),t){let{image_size:s}=this.config.vision_config;e.pixel_values=(0,u.a2)([0,3,s,s],0)}let{text_embeddings:n,image_embeddings:a,l2norm_text_embeddings:l,l2norm_image_embeddings:i}=await super.forward(e),r={};return s||(r.text_embeddings=n,r.l2norm_text_embeddings=l),t||(r.image_embeddings=a,r.l2norm_image_embeddings=i),r}}class tg extends tm{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"text_model"})}}class tx extends tm{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"vision_model"})}}class tw extends B{}class th extends tw{}class tM extends tw{}class ty extends B{}class tb extends ty{}class tk extends ty{}class tv extends B{}class tF extends tv{}class tS extends tv{}class tC extends B{}class tL extends tC{}class tP extends tC{}class tE extends B{}class tA extends tE{}class tO extends tE{}class tT extends B{}class tI extends tT{}class tq extends tT{}class tD extends B{}class tN extends tD{}class tG extends tD{}class tV extends B{}class tB extends tV{}class tj extends tV{}class t$ extends B{}class tY extends t${}class tW extends t${}class tR extends B{}class tz extends tR{}class tU extends tR{}class tQ extends B{}class tX extends tQ{}class tH extends tQ{}class tJ extends B{}class tK extends tJ{}class tZ extends tJ{}class t0 extends B{}class t2 extends t0{}class t1 extends t0{}class t3 extends B{}class t6 extends t3{}class t4 extends t3{}class t5 extends B{}class t8 extends t5{}class t9 extends t5{}class t7 extends B{}class ne extends t7{}class ns extends t7{}class nt extends B{}class nn extends nt{}class na extends nt{}class nl extends B{}class ni extends nl{}class nr extends nl{}class no extends B{}class nc extends no{}class nd extends no{}class n_ extends B{}class nu extends n_{}class np extends n_{}class nm extends B{}class nf extends nm{}class ng extends nm{}class nx extends B{forward_params=["input_ids","attention_mask","position_ids","past_key_values","pixel_values","image_grid_thw"]}class nw extends nx{get_rope_index(e,s,t,n){let{vision_config:a,image_token_id:l,video_token_id:i,vision_start_token_id:r}=this.config,o=a.spatial_merge_size??2,c=[];if(s||t){let a=e.tolist();n||(n=(0,u.oC)(e));let d=n.tolist(),_=Array.from({length:3},s=>Array.from({length:e.dims[0]},s=>Array.from({length:e.dims[1]},e=>1))),p=s?s.tolist():[],f=t?t.tolist():[],g=0,x=0;for(let e=0;e<a.length;++e){let s=a[e].filter((s,t)=>1==d[e][t]),t=s.reduce((e,s,t)=>(s==r&&e.push(t),e),[]).map(e=>s[e+1]),n=t.filter(e=>e==l).length,u=t.filter(e=>e==i).length,w=[],h=0,M=n,y=u;for(let e=0;e<t.length;++e){let e,t,n,a;let r=s.findIndex((e,s)=>s>h&&e==l),c=s.findIndex((e,s)=>s>h&&e==i),d=M>0&&-1!==r?r:s.length+1,_=y>0&&-1!==c?c:s.length+1;d<_?([t,n,a]=p[g],++g,--M,e=d):([t,n,a]=f[x],++x,--y,e=_);let[u,b,k]=[Number(t),Math.floor(Number(n)/o),Math.floor(Number(a)/o)],v=e-h,F=w.length>0?(0,m.T9)(w.at(-1))[0]+1:0;w.push(Array.from({length:3*v},(e,s)=>F+s%v));let S=v+F,C=u*b*k,L=Array.from({length:C},(e,s)=>S+Math.floor(s/(b*k))),P=Array.from({length:C},(e,s)=>S+Math.floor(s/k)%b),E=Array.from({length:C},(e,s)=>S+s%k);w.push([L,P,E].flat()),h=e+C}if(h<s.length){let e=w.length>0?(0,m.T9)(w.at(-1))[0]+1:0,t=s.length-h;w.push(Array.from({length:3*t},(s,n)=>e+n%t))}let b=w.reduce((e,s)=>e+s.length,0),k=Array(b),v=0;for(let e=0;e<3;++e)for(let s=0;s<w.length;++s){let t=w[s],n=t.length/3;for(let s=e*n;s<(e+1)*n;++s)k[v++]=t[s]}let F=0,S=d[e];for(let s=0;s<S.length;++s)if(1==S[s]){for(let t=0;t<3;++t)_[t][e][s]=k[t*b/3+F];++F}let C=(0,m.T9)(k)[0];c.push(C+1-a[e].length)}return[new u.qY("int64",_.flat(1/0),[3,e.dims[0],e.dims[1]]),new u.qY("int64",c,[c.length,1])]}if(n){let{data:e,dims:s}=q(n),t=BigInt64Array.from({length:3*e.length},(s,t)=>e[t%e.length]),a=Array.from({length:s[0]},(t,n)=>(0,m.T9)(e.subarray(s[1]*n,s[1]*(n+1)))[0]+1n+BigInt(s[1]));return[new u.qY("int64",t,[3,...s]),new u.qY("int64",a,[a.length,1])]}{let[s,t]=e.dims,n=BigInt64Array.from({length:3*s*t},(e,n)=>BigInt(Math.floor(n%t/s)));return[new u.qY("int64",n,[3,...e.dims]),(0,u.Ul)([s,1])]}}async encode_image({pixel_values:e,image_grid_thw:s}){return(await C(this.sessions.vision_encoder,{pixel_values:e,grid_thw:s})).image_features}_merge_input_ids_with_image_features(e){return T({image_token_id:this.config.image_token_id,...e})}prepare_inputs_for_generation(e,s,t){if(s.attention_mask&&!s.position_ids){if(s.past_key_values){s.pixel_values=null;let e=BigInt(Object.values(s.past_key_values)[0].dims.at(-2)),t=s.rope_deltas.map(s=>e+s);s.position_ids=(0,u.t$)([t,t,t],0)}else[s.position_ids,s.rope_deltas]=this.get_rope_index(s.input_ids,s.image_grid_thw,s.video_grid_thw,s.attention_mask)}return s}}class nh extends B{}class nM extends nh{}class ny extends nh{}class nb extends B{}class nk extends nb{}class nv extends nb{}class nF extends B{}class nS extends nF{}class nC extends nF{}class nL extends B{}class nP extends nL{}class nE extends nL{}class nA extends B{}class nO extends nA{}class nT extends nA{}class nI extends B{}class nq extends nI{}class nD extends nI{async _call(e){return new r$(await super._call(e))}}class nN extends B{}class nG extends nN{}class nV extends nN{async _call(e){return new r$(await super._call(e))}}class nB extends B{}class nj extends nB{}class n$ extends B{}class nY extends n${}class nW extends n${async _call(e){return new r$(await super._call(e))}}class nR extends B{}class nz extends nR{}class nU extends B{}class nQ extends nU{}class nX extends nU{async _call(e){return new r$(await super._call(e))}}class nH extends B{}class nJ extends nH{}class nK extends B{}class nZ extends nK{}class n0 extends nK{async _call(e){return new r$(await super._call(e))}}class n2 extends B{}class n1 extends n2{async _call(e){return new rQ(await super._call(e))}}class n3 extends B{}class n6 extends n3{}class n4 extends n3{async _call(e){return new r$(await super._call(e))}}class n5 extends B{}class n8 extends n5{}class n9 extends n5{async _call(e){return new r$(await super._call(e))}}class n7 extends B{}class ae extends n7{}class as extends n7{}class at extends B{}class an extends at{}class aa extends at{}class al extends B{}class ai extends al{}class ar extends al{async _call(e){return new r$(await super._call(e))}}class ao extends B{}class ac extends ao{}class ad extends ao{async _call(e){return new au(await super._call(e))}}class a_ extends ao{async _call(e){return new ap(await super._call(e))}}class au extends j{constructor({logits:e,pred_boxes:s}){super(),this.logits=e,this.pred_boxes=s}}class ap extends j{constructor({logits:e,pred_boxes:s,pred_masks:t}){super(),this.logits=e,this.pred_boxes=s,this.pred_masks=t}}class am extends B{}class af extends am{}class ag extends am{async _call(e){return new ax(await super._call(e))}}class ax extends j{constructor({logits:e,pred_boxes:s}){super(),this.logits=e,this.pred_boxes=s}}class aw extends B{}class ah extends aw{}class aM extends aw{async _call(e){return new ay(await super._call(e))}}class ay extends au{}class ab extends B{}class ak extends ab{}class av extends ab{async _call(e){return new r$(await super._call(e))}}class aF extends B{}class aS extends aF{}class aC extends aF{async _call(e){return new r$(await super._call(e))}}class aL extends B{}class aP extends aL{}class aE extends aL{async _call(e){return new r$(await super._call(e))}}class aA extends B{}class aO extends aA{}class aT extends aA{async _call(e){return new r$(await super._call(e))}}class aI extends B{}class aq extends aI{}class aD extends aI{}class aN extends B{}class aG extends aN{}class aV extends aN{}class aB extends B{}class aj extends aB{}class a$ extends B{}class aY extends a${}class aW extends a${}class aR extends a${}class az extends B{}class aU extends az{}class aQ extends B{}class aX extends aQ{}class aH extends aQ{}class aJ extends B{}class aK extends aJ{}class aZ extends aJ{}class a0 extends B{}class a2 extends a0{}class a1 extends B{}class a3 extends a1{}class a6 extends a1{async _call(e){return new r$(await super._call(e))}}class a4 extends B{}class a5 extends a4{}class a8 extends a4{async _call(e){return new r$(await super._call(e))}}class a9 extends B{}class a7 extends a9{}class le extends a9{async _call(e){return new r$(await super._call(e))}}class ls extends B{}class lt extends ls{}class ln extends ls{async _call(e){return new r$(await super._call(e))}}class la extends B{}class ll extends la{}class li extends B{}class lr extends li{}class lo extends li{async _call(e){return new lc(await super._call(e))}}class lc extends j{constructor({logits:e,pred_boxes:s}){super(),this.logits=e,this.pred_boxes=s}}class ld extends B{}class l_ extends ld{async get_image_embeddings({pixel_values:e}){return await A(this,{pixel_values:e})}async forward(e){if(e.image_embeddings&&e.image_positional_embeddings||(e={...e,...await this.get_image_embeddings(e)}),!e.input_labels&&e.input_points){let s=e.input_points.dims.slice(0,-1),t=s.reduce((e,s)=>e*s,1);e.input_labels=new u.qY("int64",new BigInt64Array(t).fill(1n),s)}let s={image_embeddings:e.image_embeddings,image_positional_embeddings:e.image_positional_embeddings};return e.input_points&&(s.input_points=e.input_points),e.input_labels&&(s.input_labels=e.input_labels),e.input_boxes&&(s.input_boxes=e.input_boxes),await C(this.sessions.prompt_encoder_mask_decoder,s)}async _call(e){return new lu(await super._call(e))}}class lu extends j{constructor({iou_scores:e,pred_masks:s}){super(),this.iou_scores=e,this.pred_masks=s}}class lp extends B{}class lm extends lp{}class lf extends lp{}class lg extends B{}class lx extends lg{}class lw extends lg{}class lh extends B{}class lM extends lh{}class ly extends lh{async _call(e){return new rU(await super._call(e))}}class lb extends lh{async _call(e){return new r$(await super._call(e))}}class lk extends lh{async _call(e){return new rW(await super._call(e))}}class lv extends B{}class lF extends lv{}class lS extends lv{async _call(e){return new rW(await super._call(e))}}class lC extends B{}class lL extends lC{}class lP extends B{}class lE extends lP{}class lA extends lP{async _call(e){return new rU(await super._call(e))}}class lO extends lP{async _call(e){return new r$(await super._call(e))}}class lT extends B{}class lI extends lT{}class lq extends lT{async _call(e){return new rU(await super._call(e))}}class lD extends lT{async _call(e){return new r$(await super._call(e))}}class lN extends lT{async _call(e){return new rW(await super._call(e))}}class lG extends B{}class lV extends lG{}class lB extends lG{async _call(e){return new rU(await super._call(e))}}class lj extends lG{async _call(e){return new r$(await super._call(e))}}class l$ extends lh{}class lY extends lh{async _call(e){return new rU(await super._call(e))}}class lW extends lh{async _call(e){return new r$(await super._call(e))}}class lR extends B{}class lz extends lR{}class lU extends lR{async _call(e){return new rU(await super._call(e))}}class lQ extends lR{async _call(e){return new r$(await super._call(e))}}class lX extends lR{async _call(e){return new rY(await super._call(e))}}class lH extends lR{async _call(e){return new rW(await super._call(e))}}class lJ extends B{}class lK extends lJ{}class lZ extends B{}class l0 extends lZ{}class l2 extends lZ{async generate_speech(e,s,{threshold:t=.5,minlenratio:n=0,maxlenratio:a=20,vocoder:l=null}={}){let{encoder_outputs:i,encoder_attention_mask:r}=await A(this,{input_ids:e}),o=i.dims[1]/this.config.reduction_factor,c=Math.floor(o*a),d=Math.floor(o*n),_=this.config.num_mel_bins,p=[],m=null,f=null,g=0;for(;;){++g;let e={use_cache_branch:P(!!f),output_sequence:f?f.output_sequence_out:new u.qY("float32",new Float32Array(_),[1,1,_]),encoder_attention_mask:r,speaker_embeddings:s,encoder_hidden_states:i};this.addPastKeyValues(e,m),f=await C(this.sessions.decoder_model_merged,e),m=this.getPastKeyValues(f,m);let{prob:n,spectrum:a}=f;if(p.push(a),g>=d&&(Array.from(n.data).filter(e=>e>=t).length>0||g>=c))break}let x=(0,u.$q)(p),{waveform:w}=await C(l.sessions.model,{spectrogram:x});return{spectrogram:x,waveform:w}}}class l1 extends B{main_input_name="spectrogram"}class l3 extends B{}class l6 extends l3{}class l4 extends B{}class l5 extends l4{}class l8 extends l4{}class l9 extends B{}class l7 extends l9{}class ie extends l9{}class is extends B{}class it extends is{}class ia extends is{}class il extends B{}class ii extends il{}class ir extends il{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"text_model"})}}class io extends il{static async from_pretrained(e,s={}){return super.from_pretrained(e,{...s,model_file_name:s.model_file_name??"audio_model"})}}class ic extends B{}class id extends ic{async _call(e){return new rX(await super._call(e))}}class i_ extends B{}class iu extends i_{}class ip extends i_{}class im extends B{}class ig extends im{}class ix extends im{}class iw extends B{}class ih extends iw{}class iM extends iw{async _call(e){return new r$(await super._call(e))}}class iy extends B{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"];_apply_and_filter_by_delay_pattern_mask(e){let[s,t]=e.dims,n=this.config.decoder.num_codebooks,a=t-n,l=0;for(let s=0;s<e.size;++s){if(e.data[s]===this.config.decoder.pad_token_id)continue;let i=s%t-Math.floor(s/t)%n;i>0&&i<=a&&(e.data[l++]=e.data[s])}let i=Math.floor(s/n),r=l/(i*n);return new u.qY(e.type,e.data.slice(0,l),[i,n,r])}prepare_inputs_for_generation(e,s,t){let n=structuredClone(e);for(let e=0;e<n.length;++e)for(let s=0;s<n[e].length;++s)e%this.config.decoder.num_codebooks>=s&&(n[e][s]=BigInt(this.config.decoder.pad_token_id));return null!==t.guidance_scale&&t.guidance_scale>1&&(n=n.concat(n)),super.prepare_inputs_for_generation(n,s,t)}async generate(e){let s=await super.generate(e),t=this._apply_and_filter_by_delay_pattern_mask(s).unsqueeze_(0),{audio_values:n}=await C(this.sessions.encodec_decode,{audio_codes:t});return n}}class ib extends B{}class ik extends ib{}class iv extends ib{async _call(e){return new r$(await super._call(e))}}class iF extends B{}class iS extends iF{}class iC extends iF{async _call(e){return new r$(await super._call(e))}}class iL extends B{}class iP extends iL{}class iE extends iL{async _call(e){return new r$(await super._call(e))}}class iA extends B{}class iO extends iA{}class iT extends iA{async _call(e){return new r$(await super._call(e))}}class iI extends B{}class iq extends iI{}class iD extends B{}class iN extends iD{forward_params=["input_ids","pixel_values","images_seq_mask","images_emb_mask","attention_mask","position_ids","past_key_values"];constructor(...e){super(...e),this._generation_mode="text"}async forward(e){let s;let t=this._generation_mode??"text";if("text"!==t&&e.past_key_values){let t=this.sessions.gen_img_embeds,n=(0,r.Up)({image_ids:e.input_ids},t.inputNames);s=await C(t,n)}else{let t=this.sessions.prepare_inputs_embeds,n=(0,r.Up)(e,t.inputNames);s=await C(t,n)}let n={...e,...s},a=await O(this,n),l=this.sessions["text"===t?"lm_head":"gen_head"];if(!l)throw Error(`Unable to find "${l}" generation head`);let i=await C(l,(0,r.Up)(a,l.inputNames));return{...s,...a,...i}}async generate(e){return this._generation_mode="text",super.generate(e)}async generate_images(e){this._generation_mode="image";let s=(e.inputs??e[this.main_input_name]).dims[1],t=(await super.generate(e)).slice(null,[s,null]),n=this.sessions.image_decode,{decoded_image:a}=await C(n,{generated_tokens:t}),l=a.add_(1).mul_(127.5).clamp_(0,255).to("uint8"),i=[];for(let e of l){let s=p.Y.fromTensor(e);i.push(s)}return i}}class iG extends j{constructor({char_logits:e,bpe_logits:s,wp_logits:t}){super(),this.char_logits=e,this.bpe_logits=s,this.wp_logits=t}get logits(){return[this.char_logits,this.bpe_logits,this.wp_logits]}}class iV extends B{}class iB extends iV{async _call(e){return new iG(await super._call(e))}}class ij extends B{}class i$ extends ij{}class iY extends ij{}class iW extends B{}class iR extends iW{}class iz extends iW{}class iU{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{progress_callback:s=null,config:t=null,cache_dir:a=null,local_files_only:l=!1,revision:i="main",model_file_name:r=null,subfolder:o="onnx",device:c=null,dtype:d=null,use_external_data_format:_=null,session_options:u={}}={}){let p={progress_callback:s,config:t,cache_dir:a,local_files_only:l,revision:i,model_file_name:r,subfolder:o,device:c,dtype:d,use_external_data_format:_,session_options:u};if(p.config=await n.EJ.from_pretrained(e,p),!this.MODEL_CLASS_MAPPINGS)throw Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);for(let s of this.MODEL_CLASS_MAPPINGS){let t=s.get(p.config.model_type);if(t)return await t[1].from_pretrained(e,p)}if(this.BASE_IF_FAIL)return console.warn(`Unknown model class "${p.config.model_type}", attempting to construct from base class.`),await B.from_pretrained(e,p);throw Error(`Unsupported model type: ${p.config.model_type}`)}}let iQ=new Map([["bert",["BertModel",Y]],["modernbert",["ModernBertModel",X]],["nomic_bert",["NomicBertModel",ee]],["roformer",["RoFormerModel",et]],["electra",["ElectraModel",em]],["esm",["EsmModel",eW]],["convbert",["ConvBertModel",eo]],["camembert",["CamembertModel",eM]],["deberta",["DebertaModel",eS]],["deberta-v2",["DebertaV2Model",eO]],["mpnet",["MPNetModel",e0]],["albert",["AlbertModel",ss]],["distilbert",["DistilBertModel",eG]],["roberta",["RobertaModel",sE]],["xlm",["XLMModel",sD]],["xlm-roberta",["XLMRobertaModel",s$]],["clap",["ClapModel",ii]],["clip",["CLIPModel",tl]],["clipseg",["CLIPSegModel",th]],["chinese_clip",["ChineseCLIPModel",tp]],["siglip",["SiglipModel",tc]],["jina_clip",["JinaCLIPModel",tf]],["mobilebert",["MobileBertModel",eX]],["squeezebert",["SqueezeBertModel",e5]],["wav2vec2",["Wav2Vec2Model",lM]],["wav2vec2-bert",["Wav2Vec2BertModel",lV]],["unispeech",["UniSpeechModel",lE]],["unispeech-sat",["UniSpeechSatModel",lI]],["hubert",["HubertModel",l$]],["wavlm",["WavLMModel",lz]],["audio-spectrogram-transformer",["ASTModel",sQ]],["vits",["VitsModel",id]],["pyannote",["PyAnnoteModel",lF]],["wespeaker-resnet",["WeSpeakerResNetModel",lL]],["detr",["DetrModel",ac]],["rt_detr",["RTDetrModel",af]],["table-transformer",["TableTransformerModel",ah]],["vit",["ViTModel",nq]],["ijepa",["IJepaModel",nG]],["pvt",["PvtModel",nY]],["vit_msn",["ViTMSNModel",nQ]],["vit_mae",["ViTMAEModel",nz]],["groupvit",["GroupViTModel",nJ]],["fastvit",["FastViTModel",nZ]],["mobilevit",["MobileViTModel",n6]],["mobilevitv2",["MobileViTV2Model",n8]],["owlvit",["OwlViTModel",ae]],["owlv2",["Owlv2Model",an]],["beit",["BeitModel",ai]],["deit",["DeiTModel",ak]],["hiera",["HieraModel",aS]],["convnext",["ConvNextModel",a3]],["convnextv2",["ConvNextV2Model",a5]],["dinov2",["Dinov2Model",a7]],["dinov2_with_registers",["Dinov2WithRegistersModel",lt]],["resnet",["ResNetModel",aP]],["swin",["SwinModel",aO]],["swin2sr",["Swin2SRModel",aq]],["donut-swin",["DonutSwinModel",a2]],["yolos",["YolosModel",lr]],["dpt",["DPTModel",aG]],["glpn",["GLPNModel",aK]],["hifigan",["SpeechT5HifiGan",l1]],["efficientnet",["EfficientNetModel",ih]],["decision_transformer",["DecisionTransformerModel",iq]],["patchtst",["PatchTSTForPrediction",i$]],["patchtsmixer",["PatchTSMixerForPrediction",iR]],["mobilenet_v1",["MobileNetV1Model",ik]],["mobilenet_v2",["MobileNetV2Model",iS]],["mobilenet_v3",["MobileNetV3Model",iP]],["mobilenet_v4",["MobileNetV4Model",iO]],["maskformer",["MaskFormerModel",aX]],["mgp-str",["MgpstrForSceneTextRecognition",iB]],["style_text_to_speech_2",["StyleTextToSpeech2Model",lK]]]),iX=new Map([["t5",["T5Model",si]],["longt5",["LongT5Model",sc]],["mt5",["MT5Model",su]],["bart",["BartModel",sf]],["mbart",["MBartModel",sh]],["marian",["MarianModel",lm]],["whisper",["WhisperModel",sJ]],["m2m_100",["M2M100Model",lx]],["blenderbot",["BlenderbotModel",sv]],["blenderbot-small",["BlenderbotSmallModel",sC]]]),iH=new Map([["bloom",["BloomModel",nS]],["jais",["JAISModel",tF]],["gpt2",["GPT2Model",tb]],["gptj",["GPTJModel",tI]],["gpt_bigcode",["GPTBigCodeModel",tN]],["gpt_neo",["GPTNeoModel",tL]],["gpt_neox",["GPTNeoXModel",tA]],["codegen",["CodeGenModel",tB]],["llama",["LlamaModel",tY]],["exaone",["ExaoneModel",tK]],["olmo",["OlmoModel",t6]],["olmo2",["Olmo2Model",t8]],["mobilellm",["MobileLLMModel",t2]],["granite",["GraniteModel",ne]],["cohere",["CohereModel",nn]],["gemma",["GemmaModel",ni]],["gemma2",["Gemma2Model",nc]],["helium",["HeliumModel",tz]],["glm",["GlmModel",tX]],["openelm",["OpenELMModel",nu]],["qwen2",["Qwen2Model",nf]],["phi",["PhiModel",nM]],["phi3",["Phi3Model",nk]],["mpt",["MptModel",nP]],["opt",["OPTModel",nO]],["mistral",["MistralModel",l5]],["starcoder2",["Starcoder2Model",l7]],["falcon",["FalconModel",it]],["stablelm",["StableLmModel",ig]]]),iJ=new Map([["speecht5",["SpeechT5ForSpeechToText",l0]],["whisper",["WhisperForConditionalGeneration",sK]],["moonshine",["MoonshineForConditionalGeneration",s0]]]),iK=new Map([["speecht5",["SpeechT5ForTextToSpeech",l2]]]),iZ=new Map([["vits",["VitsModel",id]],["musicgen",["MusicgenForConditionalGeneration",iy]]]),i0=new Map([["bert",["BertForSequenceClassification",R]],["modernbert",["ModernBertForSequenceClassification",J]],["roformer",["RoFormerForSequenceClassification",ea]],["electra",["ElectraForSequenceClassification",eg]],["esm",["EsmForSequenceClassification",ez]],["convbert",["ConvBertForSequenceClassification",ed]],["camembert",["CamembertForSequenceClassification",eb]],["deberta",["DebertaForSequenceClassification",eL]],["deberta-v2",["DebertaV2ForSequenceClassification",eI]],["mpnet",["MPNetForSequenceClassification",e1]],["albert",["AlbertForSequenceClassification",st]],["distilbert",["DistilBertForSequenceClassification",eV]],["roberta",["RobertaForSequenceClassification",sO]],["xlm",["XLMForSequenceClassification",sG]],["xlm-roberta",["XLMRobertaForSequenceClassification",sW]],["bart",["BartForSequenceClassification",sx]],["mbart",["MBartForSequenceClassification",sy]],["mobilebert",["MobileBertForSequenceClassification",eJ]],["squeezebert",["SqueezeBertForSequenceClassification",e9]]]),i2=new Map([["bert",["BertForTokenClassification",z]],["modernbert",["ModernBertForTokenClassification",K]],["roformer",["RoFormerForTokenClassification",el]],["electra",["ElectraForTokenClassification",ex]],["esm",["EsmForTokenClassification",eU]],["convbert",["ConvBertForTokenClassification",e_]],["camembert",["CamembertForTokenClassification",ek]],["deberta",["DebertaForTokenClassification",eP]],["deberta-v2",["DebertaV2ForTokenClassification",eq]],["mpnet",["MPNetForTokenClassification",e3]],["distilbert",["DistilBertForTokenClassification",eB]],["roberta",["RobertaForTokenClassification",sT]],["xlm",["XLMForTokenClassification",sV]],["xlm-roberta",["XLMRobertaForTokenClassification",sR]]]),i1=new Map([["t5",["T5ForConditionalGeneration",sr]],["longt5",["LongT5ForConditionalGeneration",sd]],["mt5",["MT5ForConditionalGeneration",sp]],["bart",["BartForConditionalGeneration",sg]],["mbart",["MBartForConditionalGeneration",sM]],["marian",["MarianMTModel",lf]],["m2m_100",["M2M100ForConditionalGeneration",lw]],["blenderbot",["BlenderbotForConditionalGeneration",sF]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",sL]]]),i3=new Map([["bloom",["BloomForCausalLM",nC]],["gpt2",["GPT2LMHeadModel",tk]],["jais",["JAISLMHeadModel",tS]],["gptj",["GPTJForCausalLM",tq]],["gpt_bigcode",["GPTBigCodeForCausalLM",tG]],["gpt_neo",["GPTNeoForCausalLM",tP]],["gpt_neox",["GPTNeoXForCausalLM",tO]],["codegen",["CodeGenForCausalLM",tj]],["llama",["LlamaForCausalLM",tW]],["exaone",["ExaoneForCausalLM",tZ]],["olmo",["OlmoForCausalLM",t4]],["olmo2",["Olmo2ForCausalLM",t9]],["mobilellm",["MobileLLMForCausalLM",t1]],["granite",["GraniteForCausalLM",ns]],["cohere",["CohereForCausalLM",na]],["gemma",["GemmaForCausalLM",nr]],["gemma2",["Gemma2ForCausalLM",nd]],["helium",["HeliumForCausalLM",tU]],["glm",["GlmForCausalLM",tH]],["openelm",["OpenELMForCausalLM",np]],["qwen2",["Qwen2ForCausalLM",ng]],["phi",["PhiForCausalLM",ny]],["phi3",["Phi3ForCausalLM",nv]],["mpt",["MptForCausalLM",nE]],["opt",["OPTForCausalLM",nT]],["mbart",["MBartForCausalLM",sb]],["mistral",["MistralForCausalLM",l8]],["starcoder2",["Starcoder2ForCausalLM",ie]],["falcon",["FalconForCausalLM",ia]],["trocr",["TrOCRForCausalLM",l6]],["stablelm",["StableLmForCausalLM",ix]],["phi3_v",["Phi3VForCausalLM",tn]]]),i6=new Map([["multi_modality",["MultiModalityCausalLM",iN]]]),i4=new Map([["bert",["BertForMaskedLM",W]],["modernbert",["ModernBertForMaskedLM",H]],["roformer",["RoFormerForMaskedLM",en]],["electra",["ElectraForMaskedLM",ef]],["esm",["EsmForMaskedLM",eR]],["convbert",["ConvBertForMaskedLM",ec]],["camembert",["CamembertForMaskedLM",ey]],["deberta",["DebertaForMaskedLM",eC]],["deberta-v2",["DebertaV2ForMaskedLM",eT]],["mpnet",["MPNetForMaskedLM",e2]],["albert",["AlbertForMaskedLM",sa]],["distilbert",["DistilBertForMaskedLM",e$]],["roberta",["RobertaForMaskedLM",sA]],["xlm",["XLMWithLMHeadModel",sN]],["xlm-roberta",["XLMRobertaForMaskedLM",sY]],["mobilebert",["MobileBertForMaskedLM",eH]],["squeezebert",["SqueezeBertForMaskedLM",e8]]]),i5=new Map([["bert",["BertForQuestionAnswering",U]],["roformer",["RoFormerForQuestionAnswering",ei]],["electra",["ElectraForQuestionAnswering",ew]],["convbert",["ConvBertForQuestionAnswering",eu]],["camembert",["CamembertForQuestionAnswering",ev]],["deberta",["DebertaForQuestionAnswering",eE]],["deberta-v2",["DebertaV2ForQuestionAnswering",eD]],["mpnet",["MPNetForQuestionAnswering",e6]],["albert",["AlbertForQuestionAnswering",sn]],["distilbert",["DistilBertForQuestionAnswering",ej]],["roberta",["RobertaForQuestionAnswering",sI]],["xlm",["XLMForQuestionAnswering",sB]],["xlm-roberta",["XLMRobertaForQuestionAnswering",sz]],["mobilebert",["MobileBertForQuestionAnswering",eK]],["squeezebert",["SqueezeBertForQuestionAnswering",e7]]]),i8=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",s2]],["idefics3",["Idefics3ForConditionalGeneration",ts]]]),i9=new Map([["llava",["LlavaForConditionalGeneration",s3]],["llava_onevision",["LlavaOnevisionForConditionalGeneration",s6]],["moondream1",["Moondream1ForConditionalGeneration",s4]],["florence2",["Florence2ForConditionalGeneration",s8]],["qwen2-vl",["Qwen2VLForConditionalGeneration",nw]],["idefics3",["Idefics3ForConditionalGeneration",ts]],["paligemma",["PaliGemmaForConditionalGeneration",s7]]]),i7=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",s2]]]),re=new Map([["vit",["ViTForImageClassification",nD]],["ijepa",["IJepaForImageClassification",nV]],["pvt",["PvtForImageClassification",nW]],["vit_msn",["ViTMSNForImageClassification",nX]],["fastvit",["FastViTForImageClassification",n0]],["mobilevit",["MobileViTForImageClassification",n4]],["mobilevitv2",["MobileViTV2ForImageClassification",n9]],["beit",["BeitForImageClassification",ar]],["deit",["DeiTForImageClassification",av]],["hiera",["HieraForImageClassification",aC]],["convnext",["ConvNextForImageClassification",a6]],["convnextv2",["ConvNextV2ForImageClassification",a8]],["dinov2",["Dinov2ForImageClassification",le]],["dinov2_with_registers",["Dinov2WithRegistersForImageClassification",ln]],["resnet",["ResNetForImageClassification",aE]],["swin",["SwinForImageClassification",aT]],["segformer",["SegformerForImageClassification",iu]],["efficientnet",["EfficientNetForImageClassification",iM]],["mobilenet_v1",["MobileNetV1ForImageClassification",iv]],["mobilenet_v2",["MobileNetV2ForImageClassification",iC]],["mobilenet_v3",["MobileNetV3ForImageClassification",iE]],["mobilenet_v4",["MobileNetV4ForImageClassification",iT]]]),rs=new Map([["detr",["DetrForObjectDetection",ad]],["rt_detr",["RTDetrForObjectDetection",ag]],["table-transformer",["TableTransformerForObjectDetection",aM]],["yolos",["YolosForObjectDetection",lo]]]),rt=new Map([["owlvit",["OwlViTForObjectDetection",as]],["owlv2",["Owlv2ForObjectDetection",aa]],["grounding-dino",["GroundingDinoForObjectDetection",ll]]]),rn=new Map([["detr",["DetrForSegmentation",a_]],["clipseg",["CLIPSegForImageSegmentation",tM]]]),ra=new Map([["segformer",["SegformerForSemanticSegmentation",ip]],["sapiens",["SapiensForSemanticSegmentation",aY]]]),rl=new Map([["detr",["DetrForSegmentation",a_]],["maskformer",["MaskFormerForInstanceSegmentation",aH]]]),ri=new Map([["sam",["SamModel",l_]]]),rr=new Map([["wav2vec2",["Wav2Vec2ForCTC",ly]],["wav2vec2-bert",["Wav2Vec2BertForCTC",lB]],["unispeech",["UniSpeechForCTC",lA]],["unispeech-sat",["UniSpeechSatForCTC",lq]],["wavlm",["WavLMForCTC",lU]],["hubert",["HubertForCTC",lY]]]),ro=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",lb]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",lj]],["unispeech",["UniSpeechForSequenceClassification",lO]],["unispeech-sat",["UniSpeechSatForSequenceClassification",lD]],["wavlm",["WavLMForSequenceClassification",lQ]],["hubert",["HubertForSequenceClassification",lW]],["audio-spectrogram-transformer",["ASTForAudioClassification",sX]]]),rc=new Map([["wavlm",["WavLMForXVector",lX]]]),rd=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",lN]],["wavlm",["WavLMForAudioFrameClassification",lH]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",lk]],["pyannote",["PyAnnoteForAudioFrameClassification",lS]]]),r_=new Map([["vitmatte",["VitMatteForImageMatting",n1]]]),ru=new Map([["patchtst",["PatchTSTForPrediction",iY]],["patchtsmixer",["PatchTSMixerForPrediction",iz]]]),rp=new Map([["swin2sr",["Swin2SRForImageSuperResolution",aD]]]),rm=new Map([["dpt",["DPTForDepthEstimation",aV]],["depth_anything",["DepthAnythingForDepthEstimation",aj]],["glpn",["GLPNForDepthEstimation",aZ]],["sapiens",["SapiensForDepthEstimation",aW]],["depth_pro",["DepthProForDepthEstimation",aU]]]),rf=new Map([["sapiens",["SapiensForNormalEstimation",aR]]]),rg=new Map([["vitpose",["VitPoseForPoseEstimation",nj]]]),rx=new Map([["clip",["CLIPVisionModelWithProjection",tr]],["siglip",["SiglipVisionModel",t_]],["jina_clip",["JinaCLIPVisionModel",tx]]]),rw=[[iQ,M.EncoderOnly],[iX,M.EncoderDecoder],[iH,M.DecoderOnly],[i0,M.EncoderOnly],[i2,M.EncoderOnly],[i1,M.Seq2Seq],[iJ,M.Seq2Seq],[i3,M.DecoderOnly],[i6,M.MultiModality],[i4,M.EncoderOnly],[i5,M.EncoderOnly],[i8,M.Vision2Seq],[i9,M.ImageTextToText],[re,M.EncoderOnly],[rn,M.EncoderOnly],[rl,M.EncoderOnly],[ra,M.EncoderOnly],[r_,M.EncoderOnly],[ru,M.EncoderOnly],[rp,M.EncoderOnly],[rm,M.EncoderOnly],[rf,M.EncoderOnly],[rg,M.EncoderOnly],[rs,M.EncoderOnly],[rt,M.EncoderOnly],[ri,M.MaskGeneration],[rr,M.EncoderOnly],[ro,M.EncoderOnly],[iK,M.Seq2Seq],[iZ,M.EncoderOnly],[rc,M.EncoderOnly],[rd,M.EncoderOnly],[rx,M.EncoderOnly]];for(let[e,s]of rw)for(let[t,n]of e.values())y.set(t,s),k.set(n,t),b.set(t,n);for(let[e,s,t]of[["MusicgenForConditionalGeneration",iy,M.Musicgen],["Phi3VForCausalLM",tn,M.Phi3V],["CLIPTextModelWithProjection",ti,M.EncoderOnly],["SiglipTextModel",td,M.EncoderOnly],["JinaCLIPTextModel",tg,M.EncoderOnly],["ClapTextModelWithProjection",ir,M.EncoderOnly],["ClapAudioModelWithProjection",io,M.EncoderOnly]])y.set(e,t),k.set(s,e),b.set(e,s);class rh extends iU{static MODEL_CLASS_MAPPINGS=rw.map(e=>e[0]);static BASE_IF_FAIL=!0}class rM extends iU{static MODEL_CLASS_MAPPINGS=[i0]}class ry extends iU{static MODEL_CLASS_MAPPINGS=[i2]}class rb extends iU{static MODEL_CLASS_MAPPINGS=[i1]}class rk extends iU{static MODEL_CLASS_MAPPINGS=[iJ]}class rv extends iU{static MODEL_CLASS_MAPPINGS=[iK]}class rF extends iU{static MODEL_CLASS_MAPPINGS=[iZ]}class rS extends iU{static MODEL_CLASS_MAPPINGS=[i3]}class rC extends iU{static MODEL_CLASS_MAPPINGS=[i4]}class rL extends iU{static MODEL_CLASS_MAPPINGS=[i5]}class rP extends iU{static MODEL_CLASS_MAPPINGS=[i8]}class rE extends iU{static MODEL_CLASS_MAPPINGS=[re]}class rA extends iU{static MODEL_CLASS_MAPPINGS=[rn]}class rO extends iU{static MODEL_CLASS_MAPPINGS=[ra]}class rT extends iU{static MODEL_CLASS_MAPPINGS=[rl]}class rI extends iU{static MODEL_CLASS_MAPPINGS=[rs]}class rq extends iU{static MODEL_CLASS_MAPPINGS=[rt]}class rD extends iU{static MODEL_CLASS_MAPPINGS=[rr]}class rN extends iU{static MODEL_CLASS_MAPPINGS=[ro]}class rG extends iU{static MODEL_CLASS_MAPPINGS=[i7]}class rV extends iU{static MODEL_CLASS_MAPPINGS=[rp]}class rB extends iU{static MODEL_CLASS_MAPPINGS=[rm]}class rj extends iU{static MODEL_CLASS_MAPPINGS=[rx]}class r$ extends j{constructor({logits:e,...s}){super(),this.logits=e;let t=Object.values(s);t.length>0&&(this.attentions=t)}}class rY extends j{constructor({logits:e,embeddings:s}){super(),this.logits=e,this.embeddings=s}}class rW extends j{constructor({logits:e}){super(),this.logits=e}}class rR extends j{constructor({logits:e}){super(),this.logits=e}}class rz extends j{constructor({start_logits:e,end_logits:s}){super(),this.start_logits=e,this.end_logits=s}}class rU extends j{constructor({logits:e}){super(),this.logits=e}}class rQ extends j{constructor({alphas:e}){super(),this.alphas=e}}class rX extends j{constructor({waveform:e,spectrogram:s}){super(),this.waveform=e,this.spectrogram=s}}}}]);